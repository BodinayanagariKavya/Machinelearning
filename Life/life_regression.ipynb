{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"C:/Users/hp/Desktop/pandas/lifedata.csv\")\n",
    "dataset = dataset.drop([\"Country\",\"Year\",\"GDP\", \"Population\"], axis=1).dropna()\n",
    "\n",
    "dataset = dataset.dropna(axis=0)\n",
    "label = dataset[\"Life\"]\n",
    "feature = dataset.drop(\"Life\",axis=1)\n",
    "\n",
    "# features[\"Country\"].unique()\n",
    "feature = pd.get_dummies(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(feature)\n",
    "labels = np.array(label).reshape(-1,1)\n",
    "features = torch.tensor(features, dtype = torch.float32)\n",
    "labels = torch.tensor(labels,dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(18,1)\n",
    "preds=model(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1005429.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4358e+03,  1.0717e+05, -1.7017e+03, -1.3899e+06, -1.4349e+04,\n",
      "          1.6828e+07, -1.2218e+04,  1.4044e+05, -1.3225e+04, -1.1833e+03,\n",
      "         -1.2929e+04,  1.5647e+02,  1.5735e+03,  1.5626e+03, -1.3482e+02,\n",
      "         -2.5910e+03, -1.5682e+02,  5.2527e+01]])\n",
      "tensor([-104.2956])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import mse_loss\n",
    "\n",
    "loss  = mse_loss(preds, labels)\n",
    "print(loss)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(model.weight.grad)\n",
    "print(model.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(977156.0625, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-10)\n",
    "\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "preds = model(features)\n",
    "loss = mse_loss(preds, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(52948.6797, grad_fn=<MseLossBackward0>)\n",
      "tensor(20511.8418, grad_fn=<MseLossBackward0>)\n",
      "tensor(11657.7393, grad_fn=<MseLossBackward0>)\n",
      "tensor(9157.2939, grad_fn=<MseLossBackward0>)\n",
      "tensor(8370.4053, grad_fn=<MseLossBackward0>)\n",
      "tensor(8047.2778, grad_fn=<MseLossBackward0>)\n",
      "tensor(7851.3105, grad_fn=<MseLossBackward0>)\n",
      "tensor(7691.7900, grad_fn=<MseLossBackward0>)\n",
      "tensor(7544.2324, grad_fn=<MseLossBackward0>)\n",
      "tensor(7402.0190, grad_fn=<MseLossBackward0>)\n",
      "tensor(7263.3174, grad_fn=<MseLossBackward0>)\n",
      "tensor(7127.5806, grad_fn=<MseLossBackward0>)\n",
      "tensor(6994.6733, grad_fn=<MseLossBackward0>)\n",
      "tensor(6864.4551, grad_fn=<MseLossBackward0>)\n",
      "tensor(6736.8892, grad_fn=<MseLossBackward0>)\n",
      "tensor(6611.8730, grad_fn=<MseLossBackward0>)\n",
      "tensor(6489.4766, grad_fn=<MseLossBackward0>)\n",
      "tensor(6369.4648, grad_fn=<MseLossBackward0>)\n",
      "tensor(6251.8784, grad_fn=<MseLossBackward0>)\n",
      "tensor(6136.7280, grad_fn=<MseLossBackward0>)\n",
      "tensor(6023.8667, grad_fn=<MseLossBackward0>)\n",
      "tensor(5913.2339, grad_fn=<MseLossBackward0>)\n",
      "tensor(5804.8999, grad_fn=<MseLossBackward0>)\n",
      "tensor(5698.7407, grad_fn=<MseLossBackward0>)\n",
      "tensor(5594.6729, grad_fn=<MseLossBackward0>)\n",
      "tensor(5492.7871, grad_fn=<MseLossBackward0>)\n",
      "tensor(5392.9243, grad_fn=<MseLossBackward0>)\n",
      "tensor(5295.0781, grad_fn=<MseLossBackward0>)\n",
      "tensor(5199.2104, grad_fn=<MseLossBackward0>)\n",
      "tensor(5105.2168, grad_fn=<MseLossBackward0>)\n",
      "tensor(5013.2153, grad_fn=<MseLossBackward0>)\n",
      "tensor(4923.0063, grad_fn=<MseLossBackward0>)\n",
      "tensor(4834.5859, grad_fn=<MseLossBackward0>)\n",
      "tensor(4748.0278, grad_fn=<MseLossBackward0>)\n",
      "tensor(4663.1543, grad_fn=<MseLossBackward0>)\n",
      "tensor(4580.0518, grad_fn=<MseLossBackward0>)\n",
      "tensor(4498.5796, grad_fn=<MseLossBackward0>)\n",
      "tensor(4418.7739, grad_fn=<MseLossBackward0>)\n",
      "tensor(4340.6104, grad_fn=<MseLossBackward0>)\n",
      "tensor(4263.9272, grad_fn=<MseLossBackward0>)\n",
      "tensor(4188.8579, grad_fn=<MseLossBackward0>)\n",
      "tensor(4115.2686, grad_fn=<MseLossBackward0>)\n",
      "tensor(4043.1665, grad_fn=<MseLossBackward0>)\n",
      "tensor(3972.5212, grad_fn=<MseLossBackward0>)\n",
      "tensor(3903.2727, grad_fn=<MseLossBackward0>)\n",
      "tensor(3835.3860, grad_fn=<MseLossBackward0>)\n",
      "tensor(3768.9438, grad_fn=<MseLossBackward0>)\n",
      "tensor(3703.7839, grad_fn=<MseLossBackward0>)\n",
      "tensor(3639.9053, grad_fn=<MseLossBackward0>)\n",
      "tensor(3577.3577, grad_fn=<MseLossBackward0>)\n",
      "tensor(3516.0796, grad_fn=<MseLossBackward0>)\n",
      "tensor(3456.0007, grad_fn=<MseLossBackward0>)\n",
      "tensor(3397.1548, grad_fn=<MseLossBackward0>)\n",
      "tensor(3339.4543, grad_fn=<MseLossBackward0>)\n",
      "tensor(3282.8899, grad_fn=<MseLossBackward0>)\n",
      "tensor(3227.5283, grad_fn=<MseLossBackward0>)\n",
      "tensor(3173.2434, grad_fn=<MseLossBackward0>)\n",
      "tensor(3120.0051, grad_fn=<MseLossBackward0>)\n",
      "tensor(3067.8596, grad_fn=<MseLossBackward0>)\n",
      "tensor(3016.7542, grad_fn=<MseLossBackward0>)\n",
      "tensor(2966.7019, grad_fn=<MseLossBackward0>)\n",
      "tensor(2917.6045, grad_fn=<MseLossBackward0>)\n",
      "tensor(2869.5574, grad_fn=<MseLossBackward0>)\n",
      "tensor(2822.3906, grad_fn=<MseLossBackward0>)\n",
      "tensor(2776.2053, grad_fn=<MseLossBackward0>)\n",
      "tensor(2730.9849, grad_fn=<MseLossBackward0>)\n",
      "tensor(2686.6433, grad_fn=<MseLossBackward0>)\n",
      "tensor(2643.1731, grad_fn=<MseLossBackward0>)\n",
      "tensor(2600.5188, grad_fn=<MseLossBackward0>)\n",
      "tensor(2558.7964, grad_fn=<MseLossBackward0>)\n",
      "tensor(2517.8748, grad_fn=<MseLossBackward0>)\n",
      "tensor(2477.7644, grad_fn=<MseLossBackward0>)\n",
      "tensor(2438.4700, grad_fn=<MseLossBackward0>)\n",
      "tensor(2399.9119, grad_fn=<MseLossBackward0>)\n",
      "tensor(2362.1641, grad_fn=<MseLossBackward0>)\n",
      "tensor(2325.1309, grad_fn=<MseLossBackward0>)\n",
      "tensor(2288.8613, grad_fn=<MseLossBackward0>)\n",
      "tensor(2253.3303, grad_fn=<MseLossBackward0>)\n",
      "tensor(2218.4395, grad_fn=<MseLossBackward0>)\n",
      "tensor(2184.2981, grad_fn=<MseLossBackward0>)\n",
      "tensor(2150.7917, grad_fn=<MseLossBackward0>)\n",
      "tensor(2117.9426, grad_fn=<MseLossBackward0>)\n",
      "tensor(2085.8210, grad_fn=<MseLossBackward0>)\n",
      "tensor(2054.2996, grad_fn=<MseLossBackward0>)\n",
      "tensor(2023.3848, grad_fn=<MseLossBackward0>)\n",
      "tensor(1993.1111, grad_fn=<MseLossBackward0>)\n",
      "tensor(1963.3904, grad_fn=<MseLossBackward0>)\n",
      "tensor(1934.2617, grad_fn=<MseLossBackward0>)\n",
      "tensor(1905.7545, grad_fn=<MseLossBackward0>)\n",
      "tensor(1877.7758, grad_fn=<MseLossBackward0>)\n",
      "tensor(1850.3662, grad_fn=<MseLossBackward0>)\n",
      "tensor(1823.4917, grad_fn=<MseLossBackward0>)\n",
      "tensor(1797.1259, grad_fn=<MseLossBackward0>)\n",
      "tensor(1771.2764, grad_fn=<MseLossBackward0>)\n",
      "tensor(1745.9495, grad_fn=<MseLossBackward0>)\n",
      "tensor(1721.1215, grad_fn=<MseLossBackward0>)\n",
      "tensor(1696.7886, grad_fn=<MseLossBackward0>)\n",
      "tensor(1672.9513, grad_fn=<MseLossBackward0>)\n",
      "tensor(1649.5555, grad_fn=<MseLossBackward0>)\n",
      "tensor(1626.6157, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-10)\n",
    "\n",
    "epochs = 100000\n",
    "for epoch in range(epochs):\n",
    "    preds = model(features)\n",
    "    loss = mse_loss(preds, labels)\n",
    "    \n",
    "    if (epoch+1)%1000 == 0:\n",
    "        print(loss)\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dcc23356357f8276d44a785f9d0a2aa02edb775f35b369ed56d20e41d916bba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
